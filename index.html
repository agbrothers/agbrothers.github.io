<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Greyson Brothers</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    @font-face {
      font-family: "YourCustomFont";
      src: url("fonts/YourCustomFont.woff2") format("woff2"),
           url("fonts/YourCustomFont.woff") format("woff");
      font-display: swap;
    }
    body { font-family: "YourCustomFont", ui-sans-serif, system-ui; }

    /* Custom buttons */
    .btn-link {
      display:inline-block;
      padding:0.25rem 0.5rem;
      font-size:0.75rem; /* text-xs */
      font-weight:500;
      background:transparent;
      color:#000;
      border:1px solid #F2F2F2; /* thin light outline */
      transition:color 150ms ease, border-color 150ms ease;
    }
    .btn-link:hover {
      color:#FF3D3E;
      border-color:#FF3D3E;
    }

    /* Tag colors */
    .tag-icml  { background-color: #95DB8F; color: #000; }
    .tag-rlc   { background-color: #6EB1FF; color: #000; }
    .tag-spie  { background-color: #FFCD59; color: #000; }
    .tag-neurips { background-color: #FF3D3E; color: #fff; }

    /* Uniform tag width */
    .tag-icml,.tag-rlc,.tag-spie {
      display:inline-block;
      width:4rem; /* same width for all tags */
      text-align:center;
    }
    /* Tag layout: fixed left column, colored tag stays compact */
    .tag-wrapper {
      width:5rem; /* consistent left offset */
      flex-shrink:0;
      display:flex;
      justify-content:center;
    }
    .body-text{
      font-size: 1rem;          /* change this freely */
      line-height: 1.5;
      text-align: justify;       /* the actual justify setting */
      text-justify: inter-word;  /* optional: nicer spacing where supported */
      hyphens: auto;             /* optional: helps justification look better */
    }
    /* Publication text layout */
    .pub-block > * { margin-bottom: 0.25rem; } /* small vertical gap */
    .pub-authors, .pub-venue { line-height: 1.5; }
  </style>
</head>
<body class="bg-gray-50 text-gray-800 scroll-smooth">
  <!-- Navbar -->
  <header class="fixed inset-x-0 top-0 z-50 bg-white/80 backdrop-blur shadow-md">
    <nav class="mx-auto flex max-w-4xl items-center justify-between p-4 text-sm font-medium">
      <a href="#home" class="font-bold">Greyson&nbsp;&nbsp;Brothers</a>
      <div class="hidden space-x-4 sm:block">
        <a href="#home" class="hover:text-blue-600">Home</a>
        <a href="#projects" class="hover:text-blue-600">Projects</a>
        <a href="#publications" class="hover:text-blue-600">Publications</a>
        <!-- <a href="#contact" class="hover:text-blue-600">Contact</a> -->
      </div>
    </nav>
  </header>

<main class="mx-auto max-w-4xl pt-24">
    <!-- Hero -->
    <section id="home" class="mb-24 flex flex-col md:flex-row md:items-start md:gap-8 scroll-mt-24">
      <!-- Text block -->
      <div class="flex-1">
        <h1 class="text-4xl font-extrabold tracking-tight">Greyson &nbsp;Brothers</h1>
        <p class="mt-4 body-text">
          I'm an AI/ML researcher with around 5 years of experience at Johns Hopkins University <a href="https://www.jhuapl.edu/" class="underline">Applied Physics Lab</a>. 
          I actively collaborate on autonomy research with <a href="https://johnwinder.ai/" class="underline">Dr.&nbsp;John&nbsp;Winder</a>, 
          <a href="https://willamannering.weebly.com/" class="underline">Dr.&nbsp;Willa&nbsp;Mannering</a>, 
          <a href="https://www.cs.umd.edu/people/joshmccl" class="underline">Josh&nbsp;McClellan</a>, and many others across the lab.<br><br>
          I obtained my Bachelor's in Applied Math at UCLA in 2020 and have been working toward a Master's in Computer Science part-time at Johns Hopkins, where I conducted research advised by 
          <a href="https://ep.jhu.edu/faculty/mark-fleischer/" class="underline">Prof. Mark Fleischer</a>.<br><br>
          
          My interests lie at the intersection of deep multi-agent reinforcement learning, continual learning, attention, memory mechanisms, and the hippocampus. 
          I aim to develop scalable systems that can learn rapidly from continual interactions with humans in the real world. 
        </p>
      </div>
      <!-- Profile & links -->
      <aside class="mt-8 md:mt-0 w-full md:w-80 flex-shrink-0 text-center md:text-left">
        <img src="content/profile.png" alt="Greyson Brothers portrait" class="mx-auto md:mx-0 w-80 h-80 object-cover rounded-full border border-gray-100" />
        <div class="mt-4 text-sm space-y-2">
          <div class="flex justify-center items-center gap-4 text-base">
            <a href="https://github.com/agbrothers" title="GitHub" target="_blank" rel="noopener">
              <img src="content/icon-github.png" alt="GitHub" class="w-6 h-6" />
            </a>
            <a href="https://www.linkedin.com/in/gbrothers" title="LinkedIn" target="_blank" rel="noopener">
              <img src="content/icon-linkedin.png" alt="LinkedIn" class="w-6 h-6" />
            </a>
            <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en" title="Google Scholar" target="_blank" rel="noopener">
              <img src="content/icon-scholar.png" alt="Google Scholar" class="w-6 h-6" />
            </a>
            <a href="content/cv.pdf" title="Curriculum Vitae" class="font-medium text-lg">
              <strong>CV</strong>
            </a>
            <a href="mailto:greysonbrothers@gmail.com" title="Email" class="block">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="w-6 h-6 fill-current"><path d="M2 4.5A2.5 2.5 0 0 1 4.5 2h15A2.5 2.5 0 0 1 22 4.5v15a2.5 2.5 0 0 1-2.5 2.5h-15A2.5 2.5 0 0 1 2 19.5v-15Zm2.508.063 7.992 6.105 7.992-6.105A.5.5 0 0 0 20.5 4h-15a.5.5 0 0 0-.492.563Zm-.508 1.97v12.967a.5.5 0 0 0 .5.5h15a.5.5 0 0 0 .5-.5V6.533l-8.242 6.301a.75.75 0 0 1-.916 0L4 6.533Z"/></svg>
            </a>            
          </div>
        </div>
      </aside>
    </section>


    <!-- Projects -->
    <section id="projects" class="mb-24 scroll-mt-24">
      <h2 class="text-3xl font-semibold">Projects</h2>

      <div class="mt-6 space-y-6">
        <!-- === Project 1 === -->
        <article>
          <!-- wide looping video -->
          <a href="https://www.desmos.com/3d/wvpffnqwbk" title="Desmos">
            <video
              src="content/assoc-mem-loop.mp4"  
              class="w-full rounded-lg shadow"
              autoplay
              loop
              muted
              playsinline
            ></video>
          </a> 
          <!-- blurb -->
          <br/>
          <h3 class="text-xl font-bold">An interactive associative memory. </h3> <!-- <a href="https://www.desmos.com/3d/wvpffnqwbk" title="Desmos" style="color:#FF3D3E;" class="underline">Try it</a>   -->
          <p class="mt-3 body-text">
          <!-- class="mt-4 max-w-prose text-justify text-lg leading-relaxed"> -->
            Human memory is governed by association. We tend to remember things that are highly related 
            to, or associated with, what we are currently seeing, hearing, thinking, and so on. To 
            demonstrate how models of associative memory work to my colleagues, I started tinkering 
            on a live 3D visualization tool. After falling down a Desmos rabbit hole, I found it very 
            helpful for reinforcing my own understanding, and I think it might be useful for anyone else 
            trying to build a stronger intuition for how they work. 
            
            <br/><br/>
            
            As shown above, we model memories (the light blue points) as attractors, each surrounded 
            by a big well, called a basin of attraction. Our current state of mind (the red point) follows 
            the slope of the wells downward, being pulled towards the most similar memory. This closely 
            resembles planets and gravity wells, with our thoughts following trajectories through memory 
            space. 

            <br/><br/>

            The implementation in Desmos follows the generalized dense associative memory formula outlined 
            in the ICML 2025 tutorial on <a href="https://arxiv.org/pdf/2507.06211" title="Desmos" class="underline"><em>
            Modern Methods in Associative Memory</em></a> by Krotov et al., and lets you easily swap out different 
            similarity functions, separation functions, memories, temperature, and queries to see their 
            influence on the energy landscape and recall dynamics in real time. <span style="color:#FF3D3E;" class="font-semibold">Click on the video above </span> to 
            open the interactive plot in Desmos and customize the memory landscape to your liking. 
          </p>
        </article>
      </div>
    </section>


    <!-- Publications -->
    <section id="publications" class="mb-24 scroll-mt-24">
      <h2 class="text-3xl font-semibold">Conference&nbsp;Publications</h2>
      <div class="mt-6 space-y-6">
        <!-- ICML 2025 -->
        <article class="lg border border-gray-200 bg-white p-4 shadow-sm transition hover:shadow-md">
          <div class="flex gap-3">
            <div class="tag-wrapper">
              <span class="shrink-0 self-start rounded-md px-2 py-1 text-xs font-semibold tag-icml" style="color: #ebffea;">ICML'25</span>
            </div>
            <div class="flex-1 pub-block">
              <h3 class="font-semibold">Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs</h3>
              <p class="text-xs text-gray-600 pub-authors"><strong>Greyson&nbsp;Brothers</strong>.</p>
              <p class="text-xs text-gray-600 italic pub-venue">International Conference on Machine Learning,&nbsp;ICML 2025. <span style="color:#FF3D3E;"><span class="font-bold">Spotlight</span>&nbsp;(Top&nbsp;2.6% of 12k submissions)</span></p>
              <div class="flex flex-wrap gap-2 pt-1">
                <a href="https://arxiv.org/abs/2506.09215" class="btn-link">arXiv</a>
                <a href="https://openreview.net/forum?id=8JGwoZceQs" class="btn-link">OpenReview</a>
                <a href="https://icml.cc/virtual/2025/poster/46284" class="btn-link">Presentation</a>
                <a href="https://icml.cc/media/PosterPDFs/ICML%202025/46284.png" class="btn-link">Poster</a>
                <a href="https://github.com/agbrothers/pooling" class="btn-link">Code</a>
              </div>
            </div>
          </div>
        </article>

        <!-- RLC 2025 -->
        <article class="lg border border-gray-200 bg-white p-4 shadow-sm transition hover:shadow-md">
          <div class="flex gap-3">
            <div class="tag-wrapper">
              <span class="shrink-0 self-start rounded-md px-2 py-1 text-xs font-semibold tag-rlc" style="color: #d1f5ff;">RLC'25</span>
            </div>
            <div class="flex-1 pub-block">
              <h3 class="font-semibold">PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample-Efficient&nbsp;MARL</h3>
              <p class="text-xs text-gray-600 pub-authors">Joshua&nbsp;McClellan, <strong>Greyson&nbsp;Brothers</strong>, Furong&nbsp;Huang, Pratap&nbsp;Tokekar.</p>
              <p class="text-xs text-gray-600 italic pub-venue">Reinforcement Learning Conference,&nbsp;RLC 2025.</p>
              <div class="flex flex-wrap gap-2 pt-1">
                <a href="https://arxiv.org/abs/2503.15615" class="btn-link">arXiv</a>
                <a href="https://openreview.net/forum?id=SpfX0amuzi" class="btn-link">OpenReview</a>
                <a href="https://rlj.cs.umass.edu/2025/papers/RLJ_RLC_2025_310.pdf" class="btn-link">Journal</a>
              </div>
            </div>
          </div>
        </article>

        <!-- SPIE 2025 -->
        <article class="lg border border-gray-200 bg-white p-4 shadow-sm transition hover:shadow-md">
          <div class="flex gap-3">
            <div class="tag-wrapper">
              <span class="shrink-0 self-start rounded-md px-2 py-1 text-xs font-semibold tag-spie" style="color: #fff7e3;">SPIE'25</span>
            </div>
            <div class="flex-1 pub-block">
              <h3 class="font-semibold">Beyond Human Reasoning: Bridging the Human-Machine Information Gap</h3>
              <p class="text-xs text-gray-600 pub-authors">John&nbsp;Winder, Willa&nbsp;Mannering, <strong>Greyson&nbsp;Brothers</strong>, Anish Nayak, Justin Harsono, Noah Ford, Naveed Haghani, Thomas Urban.</p>
              <p class="text-xs text-gray-600 italic pub-venue">SPIE Defense&nbsp;+ Commercial Sensing,&nbsp;2025.</p>
              <div class="flex flex-wrap gap-2 pt-1">
                <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13473/1347309/Beyond-human-reasoning-bridging-the-human-machine-information-gap/10.1117/12.3053414.short" class="btn-link">Proceedings</a>
              </div>
            </div>
          </div>
        </article>
      </div>

      <!-- Workshops -->
      <h2 class="mt-12 text-3xl font-semibold">Workshop&nbsp;Publications</h2>
      <div class="mt-6 space-y-6">
        <!-- ICML WS 2025 -->
        <article class="lg border border-gray-200 bg-white p-4 shadow-sm transition hover:shadow-md">
          <div class="flex gap-3">
            <div class="tag-wrapper">
              <span class="shrink-0 self-start rounded-md px-2 py-1 text-xs font-semibold tag-icml" style="color: #ebffea;">ICML'25</span>
            </div>
            <div class="flex-1 pub-block">
              <h3 class="font-semibold">Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs</h3>
              <p class="text-xs text-gray-600 pub-authors"><strong>Greyson&nbsp;Brothers</strong>.</p>
              <p class="text-xs text-gray-600 italic pub-venue">ICML Tokenization Workshop,&nbsp;2025. (dual submission with main track above)</p>
              <div class="flex flex-wrap gap-2 pt-1">
                <a href="https://arxiv.org/abs/2506.09215" class="btn-link">arXiv</a>
                <a href="https://openreview.net/forum?id=yRJpS6exNA" class="btn-link">OpenReview</a>
                <a href="https://tokenization-workshop.github.io/" class="btn-link">Workshop</a>
              </div>
            </div>
          </div>
        </article>

        <!-- NeurIPS WS 2024 -->
        <article class="lg border border-gray-200 bg-white p-4 shadow-sm transition hover:shadow-md">
          <div class="flex gap-3">
            <div class="tag-wrapper">
              <span class="shrink-0 self-start rounded-md px-2 py-1 text-xs font-semibold tag-neurips" style="color: #ffe2e2;">NeurIPS'24</span>
            </div>
            <div class="flex-1 pub-block">
              <h3 class="font-semibold">Uncovering Uncertainty in Transformer Inference</h3>
              <p class="text-xs text-gray-600 pub-authors"><strong>Greyson&nbsp;Brothers</strong>, Willa Mannering, Amber Tien, John Winder.</p>
              <p class="text-xs text-gray-600 italic pub-venue">NeurIPS Workshop on Foundation Model Interventions,&nbsp;2024.</p>
              <div class="flex flex-wrap gap-2 pt-1">
                <a href="https://arxiv.org/abs/2412.05768" class="btn-link">arXiv</a>
                <a href="https://openreview.net/forum?id=ceLabCFfxh" class="btn-link">OpenReview</a>
                <a href="https://neurips.cc/media/neurips-2024/Slides/104082.pdf" class="btn-link">Poster</a>
                <a href="https://sites.google.com/view/mint-2024" class="btn-link">Workshop</a>
              </div>
            </div>
          </div>
        </article>
      </div>
    </section>
